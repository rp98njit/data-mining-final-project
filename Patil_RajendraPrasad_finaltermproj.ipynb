{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Final Project\n",
    "##           - Rajendra Prasad Patil\n",
    "\n",
    "### Glossary:\n",
    "* Import libraries\n",
    "* Load dataset\n",
    "* Analysis on dataset\n",
    "* Splitting the dataset into labels and features\n",
    "* Performing normalization on dataset\n",
    "* Splitting dataset using K fold \n",
    "* Running the model\n",
    "    * SVM Model\n",
    "    * K Nearest Neighbors\n",
    "    * Random Forest Classifier\n",
    "* Output Performance Metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# SVM classifier\n",
    "from sklearn import svm\n",
    "\n",
    "# KNN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Import libraries for lstm classification\n",
    "from keras.layers import Dense, Dropout, LSTM, Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "\n",
    "# for checking the model accuracy\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = len(dataset['data'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variables  :  ['malignant' 'benign']\n",
      "Unique values of the target variable [0 1]\n",
      "Counts of the target variable : [212 357]\n"
     ]
    }
   ],
   "source": [
    "class_names = dataset['target_names']\n",
    "print('Target variables  : ', class_names)\n",
    "\n",
    "(unique, counts) = np.unique(dataset['target'], return_counts=True)\n",
    "\n",
    "print('Unique values of the target variable', unique)\n",
    "print('Counts of the target variable :', counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The dataset is suited for binary classification\n",
    "* The dataset has no skewed nature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data is split into features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset['data']\n",
    "y = dataset['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply normalization operation for numerical stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardizer = StandardScaler()\n",
    "X = standardizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics\n",
    "Function to calculate all the available performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metrics = ['True Negative', 'False Positive', 'False Negative', 'True Positivity', 'Sensitivity', 'Specificity', \n",
    "                       'Precision', 'Accuracy', 'F1 Score', 'Error Rate', 'Negative Predicted Value', 'False Positve Rate', \n",
    "                       'False Discovery Rate', 'False Negative Rate', 'Balanced Accuracy', 'True Skill Statistics', \n",
    "                       'Heidke Skill Score']\n",
    "\n",
    "def compute_performance_metrics(prediction, y_test, df, is_lstm = False):\n",
    "    \n",
    "    if is_lstm:\n",
    "        threshold = 0.80\n",
    "        for i, each in enumerate(prediction):\n",
    "            if each[0] > threshold:\n",
    "                prediction[i] = 1\n",
    "            else:\n",
    "                prediction[i] = 0\n",
    "    \n",
    "    TN, FP, FN, TP = confusion_matrix(y_test, prediction).ravel()\n",
    "    \n",
    "    sensitivity = TP / (TP + FN)\n",
    "    specificity = TN / (FP + TN)\n",
    "    precision = TP / (TP + FP)\n",
    "    accuracy =  (TP+TN) /(TP+FP+TN+FN)\n",
    "    f1_score = 2 * TP / ((2 * TP) + FP + FN)\n",
    "    error_rate = (FP + FN) / (TP + FP + FN + TN)\n",
    "    negative_predicted_value = TN / (TN + FN)\n",
    "    false_positive_rate = FP / (FP + TN)\n",
    "    false_discovery_rate = FP / (FP + TP)\n",
    "    false_negative_rate = FN / (FN + TP)\n",
    "    balanced_accuracy = 0.5 * ((TP / (TP + FN)) + (TN / (TN + FP)))\n",
    "    true_skill_statistics = ((TP / (TP + FN)) - (FP / (TN + FP)))\n",
    "    heidke_skill_score = 2 * ((TP * TN) - (FP * FN)) / (((ùëáùëÉ + ùêπùëÅ) * (ùêπùëÅ + ùëáùëÅ)) +((TP+FP) * (ùêπùëÉ + ùëáùëÅ)))\n",
    "    \n",
    "    df = df.append({performance_metrics[0]: TN, performance_metrics[1]: FP, performance_metrics[2]: FN, \n",
    "                    performance_metrics[3]: TP, performance_metrics[4]: sensitivity, performance_metrics[5]: specificity, \n",
    "                    performance_metrics[6]: precision, performance_metrics[7]: accuracy, performance_metrics[8]: f1_score, \n",
    "                    performance_metrics[9]: error_rate, performance_metrics[10]: negative_predicted_value, \n",
    "                    performance_metrics[11]: false_positive_rate, performance_metrics[12]: false_discovery_rate, \n",
    "                    performance_metrics[13]: false_negative_rate, performance_metrics[14]: \n",
    "                    balanced_accuracy, performance_metrics[15]: true_skill_statistics,\n",
    "                    performance_metrics[16]: heidke_skill_score}, ignore_index=True)\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes for performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_metrics_df = pd.DataFrame(columns=performance_metrics)\n",
    "kn_metrics_df = pd.DataFrame(columns=performance_metrics)\n",
    "rf_metrics_df = pd.DataFrame(columns=performance_metrics)\n",
    "lstm_metrics_df = pd.DataFrame(columns=performance_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm.SVC()\n",
    "for train_index, test_index in kfold.split(X):\n",
    "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "\n",
    "    # we train the algorithm with training data and training output\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    # we pass the testing data to the stored algorithm to predict the outcome\n",
    "    prediction = svm_model.predict(X_test)\n",
    "\n",
    "    # print metrics\n",
    "    svm_metrics_df = compute_performance_metrics(prediction, y_test, svm_metrics_df)\n",
    "\n",
    "svm_metrics_df.index += 1\n",
    "svm_metrics_df.loc['Average'] = svm_metrics_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Negative</th>\n",
       "      <th>False Positive</th>\n",
       "      <th>False Negative</th>\n",
       "      <th>True Positivity</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Error Rate</th>\n",
       "      <th>Negative Predicted Value</th>\n",
       "      <th>False Positve Rate</th>\n",
       "      <th>False Discovery Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>True Skill Statistics</th>\n",
       "      <th>Heidke Skill Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.944375</td>\n",
       "      <td>0.888750</td>\n",
       "      <td>0.892655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.956555</td>\n",
       "      <td>0.913110</td>\n",
       "      <td>0.913110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.958785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.958904</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.886076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.963555</td>\n",
       "      <td>0.927110</td>\n",
       "      <td>0.927110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.928121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>20.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>35.2</td>\n",
       "      <td>0.985612</td>\n",
       "      <td>0.962210</td>\n",
       "      <td>0.978164</td>\n",
       "      <td>0.977193</td>\n",
       "      <td>0.981599</td>\n",
       "      <td>0.022807</td>\n",
       "      <td>0.977236</td>\n",
       "      <td>0.037790</td>\n",
       "      <td>0.021836</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>0.973911</td>\n",
       "      <td>0.947823</td>\n",
       "      <td>0.950586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         True Negative  False Positive  False Negative  True Positivity  \\\n",
       "1                 22.0             0.0             0.0             35.0   \n",
       "2                 23.0             2.0             1.0             31.0   \n",
       "3                 15.0             1.0             1.0             40.0   \n",
       "4                 20.0             0.0             0.0             37.0   \n",
       "5                 17.0             1.0             0.0             39.0   \n",
       "6                 19.0             3.0             0.0             35.0   \n",
       "7                 22.0             1.0             1.0             33.0   \n",
       "8                 23.0             0.0             2.0             32.0   \n",
       "9                 18.0             0.0             0.0             39.0   \n",
       "10                25.0             0.0             0.0             31.0   \n",
       "Average           20.4             0.8             0.5             35.2   \n",
       "\n",
       "         Sensitivity  Specificity  Precision  Accuracy  F1 Score  Error Rate  \\\n",
       "1           1.000000     1.000000   1.000000  1.000000  1.000000    0.000000   \n",
       "2           0.968750     0.920000   0.939394  0.947368  0.953846    0.052632   \n",
       "3           0.975610     0.937500   0.975610  0.964912  0.975610    0.035088   \n",
       "4           1.000000     1.000000   1.000000  1.000000  1.000000    0.000000   \n",
       "5           1.000000     0.944444   0.975000  0.982456  0.987342    0.017544   \n",
       "6           1.000000     0.863636   0.921053  0.947368  0.958904    0.052632   \n",
       "7           0.970588     0.956522   0.970588  0.964912  0.970588    0.035088   \n",
       "8           0.941176     1.000000   1.000000  0.964912  0.969697    0.035088   \n",
       "9           1.000000     1.000000   1.000000  1.000000  1.000000    0.000000   \n",
       "10          1.000000     1.000000   1.000000  1.000000  1.000000    0.000000   \n",
       "Average     0.985612     0.962210   0.978164  0.977193  0.981599    0.022807   \n",
       "\n",
       "         Negative Predicted Value  False Positve Rate  False Discovery Rate  \\\n",
       "1                        1.000000            0.000000              0.000000   \n",
       "2                        0.958333            0.080000              0.060606   \n",
       "3                        0.937500            0.062500              0.024390   \n",
       "4                        1.000000            0.000000              0.000000   \n",
       "5                        1.000000            0.055556              0.025000   \n",
       "6                        1.000000            0.136364              0.078947   \n",
       "7                        0.956522            0.043478              0.029412   \n",
       "8                        0.920000            0.000000              0.000000   \n",
       "9                        1.000000            0.000000              0.000000   \n",
       "10                       1.000000            0.000000              0.000000   \n",
       "Average                  0.977236            0.037790              0.021836   \n",
       "\n",
       "         False Negative Rate  Balanced Accuracy  True Skill Statistics  \\\n",
       "1                   0.000000           1.000000               1.000000   \n",
       "2                   0.031250           0.944375               0.888750   \n",
       "3                   0.024390           0.956555               0.913110   \n",
       "4                   0.000000           1.000000               1.000000   \n",
       "5                   0.000000           0.972222               0.944444   \n",
       "6                   0.000000           0.931818               0.863636   \n",
       "7                   0.029412           0.963555               0.927110   \n",
       "8                   0.058824           0.970588               0.941176   \n",
       "9                   0.000000           1.000000               1.000000   \n",
       "10                  0.000000           1.000000               1.000000   \n",
       "Average             0.014388           0.973911               0.947823   \n",
       "\n",
       "         Heidke Skill Score  \n",
       "1                  1.000000  \n",
       "2                  0.892655  \n",
       "3                  0.913110  \n",
       "4                  1.000000  \n",
       "5                  0.958785  \n",
       "6                  0.886076  \n",
       "7                  0.927110  \n",
       "8                  0.928121  \n",
       "9                  1.000000  \n",
       "10                 1.000000  \n",
       "Average            0.950586  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3) # this examines 3 neighbors for putting the data into class\n",
    "\n",
    "for train_index, test_index in kfold.split(X):\n",
    "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "\n",
    "    # we train the algorithm with training data and training output\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # we pass the testing data to the stored algorithm to predict the outcome\n",
    "    prediction = model.predict(X_test)\n",
    "\n",
    "    # print metrics\n",
    "    kn_metrics_df = compute_performance_metrics(prediction, y_test, kn_metrics_df)\n",
    "\n",
    "kn_metrics_df.index += 1\n",
    "kn_metrics_df.loc['Average'] = kn_metrics_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Negative</th>\n",
       "      <th>False Positive</th>\n",
       "      <th>False Negative</th>\n",
       "      <th>True Positivity</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Error Rate</th>\n",
       "      <th>Negative Predicted Value</th>\n",
       "      <th>False Positve Rate</th>\n",
       "      <th>False Discovery Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>True Skill Statistics</th>\n",
       "      <th>Heidke Skill Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.962672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.854962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.963855</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.925305</td>\n",
       "      <td>0.850610</td>\n",
       "      <td>0.867133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.961039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.959402</td>\n",
       "      <td>0.918803</td>\n",
       "      <td>0.918803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.958904</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.886076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.963297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.927178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>19.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.994997</td>\n",
       "      <td>0.930415</td>\n",
       "      <td>0.959341</td>\n",
       "      <td>0.970113</td>\n",
       "      <td>0.976513</td>\n",
       "      <td>0.029887</td>\n",
       "      <td>0.987778</td>\n",
       "      <td>0.069585</td>\n",
       "      <td>0.040659</td>\n",
       "      <td>0.005003</td>\n",
       "      <td>0.962706</td>\n",
       "      <td>0.925412</td>\n",
       "      <td>0.934116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         True Negative  False Positive  False Negative  True Positivity  \\\n",
       "1                 21.0             1.0             0.0             35.0   \n",
       "2                 21.0             4.0             0.0             32.0   \n",
       "3                 14.0             2.0             1.0             40.0   \n",
       "4                 19.0             1.0             0.0             37.0   \n",
       "5                 17.0             1.0             1.0             38.0   \n",
       "6                 19.0             3.0             0.0             35.0   \n",
       "7                 22.0             1.0             0.0             34.0   \n",
       "8                 23.0             0.0             0.0             34.0   \n",
       "9                 18.0             0.0             0.0             39.0   \n",
       "10                23.0             2.0             0.0             31.0   \n",
       "Average           19.7             1.5             0.2             35.5   \n",
       "\n",
       "         Sensitivity  Specificity  Precision  Accuracy  F1 Score  Error Rate  \\\n",
       "1           1.000000     0.954545   0.972222  0.982456  0.985915    0.017544   \n",
       "2           1.000000     0.840000   0.888889  0.929825  0.941176    0.070175   \n",
       "3           0.975610     0.875000   0.952381  0.947368  0.963855    0.052632   \n",
       "4           1.000000     0.950000   0.973684  0.982456  0.986667    0.017544   \n",
       "5           0.974359     0.944444   0.974359  0.964912  0.974359    0.035088   \n",
       "6           1.000000     0.863636   0.921053  0.947368  0.958904    0.052632   \n",
       "7           1.000000     0.956522   0.971429  0.982456  0.985507    0.017544   \n",
       "8           1.000000     1.000000   1.000000  1.000000  1.000000    0.000000   \n",
       "9           1.000000     1.000000   1.000000  1.000000  1.000000    0.000000   \n",
       "10          1.000000     0.920000   0.939394  0.964286  0.968750    0.035714   \n",
       "Average     0.994997     0.930415   0.959341  0.970113  0.976513    0.029887   \n",
       "\n",
       "         Negative Predicted Value  False Positve Rate  False Discovery Rate  \\\n",
       "1                        1.000000            0.045455              0.027778   \n",
       "2                        1.000000            0.160000              0.111111   \n",
       "3                        0.933333            0.125000              0.047619   \n",
       "4                        1.000000            0.050000              0.026316   \n",
       "5                        0.944444            0.055556              0.025641   \n",
       "6                        1.000000            0.136364              0.078947   \n",
       "7                        1.000000            0.043478              0.028571   \n",
       "8                        1.000000            0.000000              0.000000   \n",
       "9                        1.000000            0.000000              0.000000   \n",
       "10                       1.000000            0.080000              0.060606   \n",
       "Average                  0.987778            0.069585              0.040659   \n",
       "\n",
       "         False Negative Rate  Balanced Accuracy  True Skill Statistics  \\\n",
       "1                   0.000000           0.977273               0.954545   \n",
       "2                   0.000000           0.920000               0.840000   \n",
       "3                   0.024390           0.925305               0.850610   \n",
       "4                   0.000000           0.975000               0.950000   \n",
       "5                   0.025641           0.959402               0.918803   \n",
       "6                   0.000000           0.931818               0.863636   \n",
       "7                   0.000000           0.978261               0.956522   \n",
       "8                   0.000000           1.000000               1.000000   \n",
       "9                   0.000000           1.000000               1.000000   \n",
       "10                  0.000000           0.960000               0.920000   \n",
       "Average             0.005003           0.962706               0.925412   \n",
       "\n",
       "         Heidke Skill Score  \n",
       "1                  0.962672  \n",
       "2                  0.854962  \n",
       "3                  0.867133  \n",
       "4                  0.961039  \n",
       "5                  0.918803  \n",
       "6                  0.886076  \n",
       "7                  0.963297  \n",
       "8                  1.000000  \n",
       "9                  1.000000  \n",
       "10                 0.927178  \n",
       "Average            0.934116  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Gaussian Classifier\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "for train_index, test_index in kfold.split(X):\n",
    "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "\n",
    "    # we train the algorithm with training data and training output\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # we pass the testing data to the stored algorithm to predict the outcome\n",
    "    prediction = model.predict(X_test)\n",
    "\n",
    "    # print metrics\n",
    "    rf_metrics_df = compute_performance_metrics(prediction, y_test, rf_metrics_df)\n",
    "\n",
    "rf_metrics_df.index += 1\n",
    "rf_metrics_df.loc['Average'] = rf_metrics_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Negative</th>\n",
       "      <th>False Positive</th>\n",
       "      <th>False Negative</th>\n",
       "      <th>True Positivity</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Error Rate</th>\n",
       "      <th>Negative Predicted Value</th>\n",
       "      <th>False Positve Rate</th>\n",
       "      <th>False Discovery Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>True Skill Statistics</th>\n",
       "      <th>Heidke Skill Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.955224</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.891704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.964218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.944360</td>\n",
       "      <td>0.888720</td>\n",
       "      <td>0.872102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.961039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.946581</td>\n",
       "      <td>0.893162</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.880519</td>\n",
       "      <td>0.761039</td>\n",
       "      <td>0.774108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.963297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.920077</td>\n",
       "      <td>0.840153</td>\n",
       "      <td>0.852140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.7</td>\n",
       "      <td>0.972767</td>\n",
       "      <td>0.943621</td>\n",
       "      <td>0.967205</td>\n",
       "      <td>0.961404</td>\n",
       "      <td>0.969554</td>\n",
       "      <td>0.038596</td>\n",
       "      <td>0.950947</td>\n",
       "      <td>0.056379</td>\n",
       "      <td>0.032795</td>\n",
       "      <td>0.027233</td>\n",
       "      <td>0.958194</td>\n",
       "      <td>0.916388</td>\n",
       "      <td>0.915861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         True Negative  False Positive  False Negative  True Positivity  \\\n",
       "1                 22.0             0.0             3.0             32.0   \n",
       "2                 24.0             1.0             0.0             32.0   \n",
       "3                 15.0             1.0             2.0             39.0   \n",
       "4                 19.0             1.0             0.0             37.0   \n",
       "5                 17.0             1.0             2.0             37.0   \n",
       "6                 18.0             4.0             2.0             33.0   \n",
       "7                 22.0             1.0             0.0             34.0   \n",
       "8                 20.0             3.0             1.0             33.0   \n",
       "9                 18.0             0.0             0.0             39.0   \n",
       "10                25.0             0.0             0.0             31.0   \n",
       "Average           20.0             1.2             1.0             34.7   \n",
       "\n",
       "         Sensitivity  Specificity  Precision  Accuracy  F1 Score  Error Rate  \\\n",
       "1           0.914286     1.000000   1.000000  0.947368  0.955224    0.052632   \n",
       "2           1.000000     0.960000   0.969697  0.982456  0.984615    0.017544   \n",
       "3           0.951220     0.937500   0.975000  0.947368  0.962963    0.052632   \n",
       "4           1.000000     0.950000   0.973684  0.982456  0.986667    0.017544   \n",
       "5           0.948718     0.944444   0.973684  0.947368  0.961039    0.052632   \n",
       "6           0.942857     0.818182   0.891892  0.894737  0.916667    0.105263   \n",
       "7           1.000000     0.956522   0.971429  0.982456  0.985507    0.017544   \n",
       "8           0.970588     0.869565   0.916667  0.929825  0.942857    0.070175   \n",
       "9           1.000000     1.000000   1.000000  1.000000  1.000000    0.000000   \n",
       "10          1.000000     1.000000   1.000000  1.000000  1.000000    0.000000   \n",
       "Average     0.972767     0.943621   0.967205  0.961404  0.969554    0.038596   \n",
       "\n",
       "         Negative Predicted Value  False Positve Rate  False Discovery Rate  \\\n",
       "1                        0.880000            0.000000              0.000000   \n",
       "2                        1.000000            0.040000              0.030303   \n",
       "3                        0.882353            0.062500              0.025000   \n",
       "4                        1.000000            0.050000              0.026316   \n",
       "5                        0.894737            0.055556              0.026316   \n",
       "6                        0.900000            0.181818              0.108108   \n",
       "7                        1.000000            0.043478              0.028571   \n",
       "8                        0.952381            0.130435              0.083333   \n",
       "9                        1.000000            0.000000              0.000000   \n",
       "10                       1.000000            0.000000              0.000000   \n",
       "Average                  0.950947            0.056379              0.032795   \n",
       "\n",
       "         False Negative Rate  Balanced Accuracy  True Skill Statistics  \\\n",
       "1                   0.085714           0.957143               0.914286   \n",
       "2                   0.000000           0.980000               0.960000   \n",
       "3                   0.048780           0.944360               0.888720   \n",
       "4                   0.000000           0.975000               0.950000   \n",
       "5                   0.051282           0.946581               0.893162   \n",
       "6                   0.057143           0.880519               0.761039   \n",
       "7                   0.000000           0.978261               0.956522   \n",
       "8                   0.029412           0.920077               0.840153   \n",
       "9                   0.000000           1.000000               1.000000   \n",
       "10                  0.000000           1.000000               1.000000   \n",
       "Average             0.027233           0.958194               0.916388   \n",
       "\n",
       "         Heidke Skill Score  \n",
       "1                  0.891704  \n",
       "2                  0.964218  \n",
       "3                  0.872102  \n",
       "4                  0.961039  \n",
       "5                  0.880000  \n",
       "6                  0.774108  \n",
       "7                  0.963297  \n",
       "8                  0.852140  \n",
       "9                  1.000000  \n",
       "10                 1.000000  \n",
       "Average            0.915861  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 4s 23ms/step - loss: 0.5242 - accuracy: 0.8652 - val_loss: 0.3321 - val_accuracy: 0.8947\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3274 - accuracy: 0.8965 - val_loss: 0.2557 - val_accuracy: 0.9123\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.3026 - accuracy: 0.8965 - val_loss: 0.2491 - val_accuracy: 0.9123\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2851 - accuracy: 0.9062 - val_loss: 0.2335 - val_accuracy: 0.9298\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2854 - accuracy: 0.9102 - val_loss: 0.2548 - val_accuracy: 0.9123\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2841 - accuracy: 0.9102 - val_loss: 0.2355 - val_accuracy: 0.9298\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.2496 - accuracy: 0.9180 - val_loss: 0.2111 - val_accuracy: 0.9298\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2288 - accuracy: 0.9258 - val_loss: 0.2005 - val_accuracy: 0.9474\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2237 - accuracy: 0.9258 - val_loss: 0.2024 - val_accuracy: 0.9298\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2216 - accuracy: 0.9375 - val_loss: 0.1948 - val_accuracy: 0.9298\n",
      "****************************************************************************************************\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.2210 - accuracy: 0.9336 - val_loss: 0.2731 - val_accuracy: 0.8947\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.2088 - accuracy: 0.9395 - val_loss: 0.2665 - val_accuracy: 0.9123\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2187 - accuracy: 0.9336 - val_loss: 0.2626 - val_accuracy: 0.9123\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1985 - accuracy: 0.9395 - val_loss: 0.2268 - val_accuracy: 0.9298\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1883 - accuracy: 0.9355 - val_loss: 0.2137 - val_accuracy: 0.9298\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1872 - accuracy: 0.9395 - val_loss: 0.2644 - val_accuracy: 0.9123\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2097 - accuracy: 0.9316 - val_loss: 0.2100 - val_accuracy: 0.9298\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1953 - accuracy: 0.9316 - val_loss: 0.2072 - val_accuracy: 0.9298\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1903 - accuracy: 0.9414 - val_loss: 0.2217 - val_accuracy: 0.9123\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1825 - accuracy: 0.9492 - val_loss: 0.1949 - val_accuracy: 0.9123\n",
      "****************************************************************************************************\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.2076 - accuracy: 0.9199 - val_loss: 0.2607 - val_accuracy: 0.8947\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.2124 - accuracy: 0.9355 - val_loss: 0.2711 - val_accuracy: 0.9123\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1988 - accuracy: 0.9414 - val_loss: 0.2643 - val_accuracy: 0.8772\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1726 - accuracy: 0.9414 - val_loss: 0.2506 - val_accuracy: 0.8947\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1724 - accuracy: 0.9473 - val_loss: 0.2388 - val_accuracy: 0.8772\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1702 - accuracy: 0.9453 - val_loss: 0.2481 - val_accuracy: 0.9123\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1692 - accuracy: 0.9395 - val_loss: 0.2263 - val_accuracy: 0.8947\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1744 - accuracy: 0.9473 - val_loss: 0.2342 - val_accuracy: 0.8772\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1613 - accuracy: 0.9473 - val_loss: 0.2397 - val_accuracy: 0.9123\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1575 - accuracy: 0.9453 - val_loss: 0.2398 - val_accuracy: 0.8947\n",
      "****************************************************************************************************\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1755 - accuracy: 0.9453 - val_loss: 0.1009 - val_accuracy: 0.9474\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1524 - accuracy: 0.9414 - val_loss: 0.1033 - val_accuracy: 0.9474\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1646 - accuracy: 0.9434 - val_loss: 0.1022 - val_accuracy: 0.9474\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1533 - accuracy: 0.9473 - val_loss: 0.0925 - val_accuracy: 0.9649\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1652 - accuracy: 0.9414 - val_loss: 0.1113 - val_accuracy: 0.9474\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1400 - accuracy: 0.9492 - val_loss: 0.1103 - val_accuracy: 0.9649\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1457 - accuracy: 0.9492 - val_loss: 0.1138 - val_accuracy: 0.9474\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1516 - accuracy: 0.9453 - val_loss: 0.1112 - val_accuracy: 0.9474\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1491 - accuracy: 0.9453 - val_loss: 0.1091 - val_accuracy: 0.9649\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1509 - accuracy: 0.9492 - val_loss: 0.1012 - val_accuracy: 0.9649\n",
      "****************************************************************************************************\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1362 - accuracy: 0.9512 - val_loss: 0.1394 - val_accuracy: 0.9474\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1369 - accuracy: 0.9531 - val_loss: 0.1539 - val_accuracy: 0.9474\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1491 - accuracy: 0.9512 - val_loss: 0.1386 - val_accuracy: 0.9474\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1250 - accuracy: 0.9531 - val_loss: 0.1405 - val_accuracy: 0.9474\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1430 - accuracy: 0.9492 - val_loss: 0.1481 - val_accuracy: 0.9474\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1173 - accuracy: 0.9570 - val_loss: 0.1464 - val_accuracy: 0.9474\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1288 - accuracy: 0.9609 - val_loss: 0.1375 - val_accuracy: 0.9474\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1294 - accuracy: 0.9707 - val_loss: 0.1457 - val_accuracy: 0.9298\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1236 - accuracy: 0.9688 - val_loss: 0.1166 - val_accuracy: 0.9649\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1370 - accuracy: 0.9629 - val_loss: 0.1710 - val_accuracy: 0.9298\n",
      "****************************************************************************************************\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1309 - accuracy: 0.9551 - val_loss: 0.2213 - val_accuracy: 0.8947\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1226 - accuracy: 0.9609 - val_loss: 0.2038 - val_accuracy: 0.8947\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1176 - accuracy: 0.9590 - val_loss: 0.1913 - val_accuracy: 0.9298\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1117 - accuracy: 0.9629 - val_loss: 0.2180 - val_accuracy: 0.9123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1094 - accuracy: 0.9688 - val_loss: 0.2035 - val_accuracy: 0.9298\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1047 - accuracy: 0.9668 - val_loss: 0.2173 - val_accuracy: 0.9123\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1214 - accuracy: 0.9531 - val_loss: 0.2254 - val_accuracy: 0.9123\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1052 - accuracy: 0.9629 - val_loss: 0.2213 - val_accuracy: 0.9298\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1044 - accuracy: 0.9707 - val_loss: 0.2235 - val_accuracy: 0.9298\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1110 - accuracy: 0.9609 - val_loss: 0.2265 - val_accuracy: 0.9298\n",
      "****************************************************************************************************\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1121 - accuracy: 0.9609 - val_loss: 0.1480 - val_accuracy: 0.9649\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1072 - accuracy: 0.9531 - val_loss: 0.1473 - val_accuracy: 0.9649\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1112 - accuracy: 0.9590 - val_loss: 0.1318 - val_accuracy: 0.9649\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1088 - accuracy: 0.9648 - val_loss: 0.1496 - val_accuracy: 0.9649\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1247 - accuracy: 0.9570 - val_loss: 0.1533 - val_accuracy: 0.9649\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1169 - accuracy: 0.9590 - val_loss: 0.1420 - val_accuracy: 0.9474\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1176 - accuracy: 0.9590 - val_loss: 0.1508 - val_accuracy: 0.9649\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1158 - accuracy: 0.9570 - val_loss: 0.1639 - val_accuracy: 0.9649\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1172 - accuracy: 0.9629 - val_loss: 0.1750 - val_accuracy: 0.9649\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1168 - accuracy: 0.9531 - val_loss: 0.1578 - val_accuracy: 0.9649\n",
      "****************************************************************************************************\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1249 - accuracy: 0.9629 - val_loss: 0.0494 - val_accuracy: 0.9825\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1200 - accuracy: 0.9570 - val_loss: 0.0503 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1186 - accuracy: 0.9629 - val_loss: 0.0525 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.1260 - accuracy: 0.95 - 1s 12ms/step - loss: 0.1235 - accuracy: 0.9609 - val_loss: 0.0504 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1248 - accuracy: 0.9551 - val_loss: 0.0503 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1218 - accuracy: 0.9609 - val_loss: 0.0514 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1115 - accuracy: 0.9668 - val_loss: 0.0533 - val_accuracy: 0.9825\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1152 - accuracy: 0.9531 - val_loss: 0.0523 - val_accuracy: 0.9649\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1201 - accuracy: 0.9570 - val_loss: 0.0646 - val_accuracy: 0.9649\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1138 - accuracy: 0.9629 - val_loss: 0.0529 - val_accuracy: 1.0000\n",
      "****************************************************************************************************\n",
      "Epoch 1/10\n",
      "64/64 [==============================] - 1s 13ms/step - loss: 0.1240 - accuracy: 0.9551 - val_loss: 0.0454 - val_accuracy: 0.9825\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.0992 - accuracy: 0.9551 - val_loss: 0.0462 - val_accuracy: 0.9825\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1221 - accuracy: 0.9609 - val_loss: 0.0440 - val_accuracy: 0.9825\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1270 - accuracy: 0.9570 - val_loss: 0.0457 - val_accuracy: 0.9825\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1256 - accuracy: 0.9551 - val_loss: 0.0396 - val_accuracy: 0.9825\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1182 - accuracy: 0.9590 - val_loss: 0.0421 - val_accuracy: 0.9825\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1252 - accuracy: 0.9609 - val_loss: 0.0492 - val_accuracy: 0.9649\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1312 - accuracy: 0.9570 - val_loss: 0.0492 - val_accuracy: 0.9825\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1267 - accuracy: 0.9531 - val_loss: 0.0300 - val_accuracy: 0.9825\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.1155 - accuracy: 0.9688 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
      "****************************************************************************************************\n",
      "Epoch 1/10\n",
      "65/65 [==============================] - 3s 29ms/step - loss: 0.1040 - accuracy: 0.9669 - val_loss: 0.0653 - val_accuracy: 0.9643\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 1s 19ms/step - loss: 0.1083 - accuracy: 0.9610 - val_loss: 0.0502 - val_accuracy: 0.9821\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 1s 19ms/step - loss: 0.1097 - accuracy: 0.9649 - val_loss: 0.0671 - val_accuracy: 0.9643\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 1s 19ms/step - loss: 0.1029 - accuracy: 0.9708 - val_loss: 0.0779 - val_accuracy: 0.9643\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 1s 19ms/step - loss: 0.1110 - accuracy: 0.9708 - val_loss: 0.0700 - val_accuracy: 0.9821\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 1s 19ms/step - loss: 0.0800 - accuracy: 0.9747 - val_loss: 0.0862 - val_accuracy: 0.9821\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 1s 19ms/step - loss: 0.0983 - accuracy: 0.9708 - val_loss: 0.0415 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 1s 19ms/step - loss: 0.0929 - accuracy: 0.9747 - val_loss: 0.0433 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 1s 19ms/step - loss: 0.1022 - accuracy: 0.9688 - val_loss: 0.0585 - val_accuracy: 0.9821\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 1s 19ms/step - loss: 0.1026 - accuracy: 0.9688 - val_loss: 0.0445 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(20, input_shape=(input_length, 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "for train_index, test_index in kfold.split(X):\n",
    "    print('*'*100)\n",
    "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "\n",
    "    # we train the algorithm with training data and training output\n",
    "    model.fit(X_train, y_train, batch_size=8, epochs=10, validation_data=(X_test, y_test), verbose = 1)\n",
    "\n",
    "    # we pass the testing data to the stored algorithm to predict the outcome\n",
    "    prediction = model.predict(X_test)\n",
    "    \n",
    "    # print metrics\n",
    "    lstm_metrics_df = compute_performance_metrics(prediction, y_test, lstm_metrics_df, is_lstm=True)\n",
    "\n",
    "lstm_metrics_df.index += 1\n",
    "lstm_metrics_df.loc['Average'] = lstm_metrics_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Negative</th>\n",
       "      <th>False Positive</th>\n",
       "      <th>False Negative</th>\n",
       "      <th>True Positivity</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Error Rate</th>\n",
       "      <th>Negative Predicted Value</th>\n",
       "      <th>False Positve Rate</th>\n",
       "      <th>False Discovery Rate</th>\n",
       "      <th>False Negative Rate</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>True Skill Statistics</th>\n",
       "      <th>Heidke Skill Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.934416</td>\n",
       "      <td>0.868831</td>\n",
       "      <td>0.854406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.908750</td>\n",
       "      <td>0.817500</td>\n",
       "      <td>0.821092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.895579</td>\n",
       "      <td>0.791159</td>\n",
       "      <td>0.722338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.961039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.933761</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>0.842324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.925974</td>\n",
       "      <td>0.851948</td>\n",
       "      <td>0.851948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.934143</td>\n",
       "      <td>0.868286</td>\n",
       "      <td>0.856242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.892924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>0.928297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>20.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>33.3</td>\n",
       "      <td>0.933039</td>\n",
       "      <td>0.953210</td>\n",
       "      <td>0.970927</td>\n",
       "      <td>0.940288</td>\n",
       "      <td>0.951014</td>\n",
       "      <td>0.059712</td>\n",
       "      <td>0.895558</td>\n",
       "      <td>0.046790</td>\n",
       "      <td>0.029073</td>\n",
       "      <td>0.066961</td>\n",
       "      <td>0.943125</td>\n",
       "      <td>0.886249</td>\n",
       "      <td>0.873061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         True Negative  False Positive  False Negative  True Positivity  \\\n",
       "1                 21.0             1.0             3.0             32.0   \n",
       "2                 22.0             3.0             2.0             30.0   \n",
       "3                 15.0             1.0             6.0             35.0   \n",
       "4                 19.0             1.0             0.0             37.0   \n",
       "5                 17.0             1.0             3.0             36.0   \n",
       "6                 20.0             2.0             2.0             33.0   \n",
       "7                 22.0             1.0             3.0             31.0   \n",
       "8                 23.0             0.0             3.0             31.0   \n",
       "9                 18.0             0.0             0.0             39.0   \n",
       "10                25.0             0.0             2.0             29.0   \n",
       "Average           20.2             1.0             2.4             33.3   \n",
       "\n",
       "         Sensitivity  Specificity  Precision  Accuracy  F1 Score  Error Rate  \\\n",
       "1           0.914286     0.954545   0.969697  0.929825  0.941176    0.070175   \n",
       "2           0.937500     0.880000   0.909091  0.912281  0.923077    0.087719   \n",
       "3           0.853659     0.937500   0.972222  0.877193  0.909091    0.122807   \n",
       "4           1.000000     0.950000   0.973684  0.982456  0.986667    0.017544   \n",
       "5           0.923077     0.944444   0.972973  0.929825  0.947368    0.070175   \n",
       "6           0.942857     0.909091   0.942857  0.929825  0.942857    0.070175   \n",
       "7           0.911765     0.956522   0.968750  0.929825  0.939394    0.070175   \n",
       "8           0.911765     1.000000   1.000000  0.947368  0.953846    0.052632   \n",
       "9           1.000000     1.000000   1.000000  1.000000  1.000000    0.000000   \n",
       "10          0.935484     1.000000   1.000000  0.964286  0.966667    0.035714   \n",
       "Average     0.933039     0.953210   0.970927  0.940288  0.951014    0.059712   \n",
       "\n",
       "         Negative Predicted Value  False Positve Rate  False Discovery Rate  \\\n",
       "1                        0.875000            0.045455              0.030303   \n",
       "2                        0.916667            0.120000              0.090909   \n",
       "3                        0.714286            0.062500              0.027778   \n",
       "4                        1.000000            0.050000              0.026316   \n",
       "5                        0.850000            0.055556              0.027027   \n",
       "6                        0.909091            0.090909              0.057143   \n",
       "7                        0.880000            0.043478              0.031250   \n",
       "8                        0.884615            0.000000              0.000000   \n",
       "9                        1.000000            0.000000              0.000000   \n",
       "10                       0.925926            0.000000              0.000000   \n",
       "Average                  0.895558            0.046790              0.029073   \n",
       "\n",
       "         False Negative Rate  Balanced Accuracy  True Skill Statistics  \\\n",
       "1                   0.085714           0.934416               0.868831   \n",
       "2                   0.062500           0.908750               0.817500   \n",
       "3                   0.146341           0.895579               0.791159   \n",
       "4                   0.000000           0.975000               0.950000   \n",
       "5                   0.076923           0.933761               0.867521   \n",
       "6                   0.057143           0.925974               0.851948   \n",
       "7                   0.088235           0.934143               0.868286   \n",
       "8                   0.088235           0.955882               0.911765   \n",
       "9                   0.000000           1.000000               1.000000   \n",
       "10                  0.064516           0.967742               0.935484   \n",
       "Average             0.066961           0.943125               0.886249   \n",
       "\n",
       "         Heidke Skill Score  \n",
       "1                  0.854406  \n",
       "2                  0.821092  \n",
       "3                  0.722338  \n",
       "4                  0.961039  \n",
       "5                  0.842324  \n",
       "6                  0.851948  \n",
       "7                  0.856242  \n",
       "8                  0.892924  \n",
       "9                  1.000000  \n",
       "10                 0.928297  \n",
       "Average            0.873061  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "* I consider balanced accuracy to be the optimal metric to find the best model.\n",
    "* The case being, SVM is the model which is giving the highest balanced accuracy.\n",
    "\n",
    "### Why is SVM performing better?\n",
    "* SVM doesn't get affected by outliers\n",
    "* It does not suffer from overfitting\n",
    "* It is more efficient than other ML algorithms listed here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
